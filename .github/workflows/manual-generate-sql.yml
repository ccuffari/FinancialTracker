# .github/workflows/generate-db-structure.yml
name: Generate Database Structure

on:
  workflow_dispatch:
    inputs:
      branch:
        description: "Branch da utilizzare"
        required: true
        default: "main"
        type: string
      python_version:
        description: "Versione Python"
        required: true
        default: "3.10"
        type: choice
        options:
          - "3.8"
          - "3.9"
          - "3.10"
          - "3.11"
          - "3.12"
      deploy_to_neon:
        description: "Deploy su PostgreSQL Neon (necessario per Provisioning/ETL)"
        required: true
        default: false
        type: boolean
      populate_data:
        description: "Popola tabelle con dati Excel (usato dall'ETL)"
        required: true
        default: true
        type: boolean
      run_data_modeling:
        description: "Esegui Data Modeling (genera SQL DDL)"
        required: true
        default: true
        type: boolean
      run_data_provisioning:
        description: "Esegui Data Provisioning (deploy dello schema su Neon)"
        required: true
        default: false
        type: boolean
      run_etl:
        description: "Esegui ETL (popolamento tabelle)"
        required: true
        default: false
        type: boolean

jobs:
  initialization:
    name: Initialization & validation
    runs-on: ubuntu-latest
    permissions:
      contents: write
    outputs:
      branch: ${{ github.event.inputs.branch }}
      python_version: ${{ github.event.inputs.python_version }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Validate user selections (at least one of Modeling/Provisioning/ETL)
        run: |
          echo "Validating workflow inputs..."
          RM="${{ github.event.inputs.run_data_modeling }}"
          RP="${{ github.event.inputs.run_data_provisioning }}"
          RE="${{ github.event.inputs.run_etl }}"
          DEPLOY="${{ github.event.inputs.deploy_to_neon }}"

          echo " - run_data_modeling: $RM"
          echo " - run_data_provisioning: $RP"
          echo " - run_etl: $RE"
          echo " - deploy_to_neon: $DEPLOY"

          if [ "$RM" != "true" ] && [ "$RP" != "true" ] && [ "$RE" != "true" ]; then
            echo "‚ùå Errore: almeno uno tra Data Modeling, Data Provisioning o ETL deve essere selezionato."
            exit 1
          fi

          if { [ "$RP" = "true" ] || [ "$RE" = "true" ]; } && [ "$DEPLOY" != "true" ]; then
            echo "‚ùå Errore: Data Provisioning ed ETL richiedono 'deploy_to_neon' = true."
            exit 1
          fi

          echo "‚úÖ Validazione completata."

      - name: Verify Excel file exists (quick check)
        run: |
          if [ ! -f "data/financialTracker.xlsx" ]; then
            echo "‚ö†Ô∏è File data/financialTracker.xlsx non trovato in repo."
          else
            echo "‚úÖ File Excel trovato"
            ls -la data/financialTracker.xlsx
          fi

      - name: Create output directory
        run: |
          mkdir -p sql/ddl
          echo "‚úÖ Directory sql/ddl creata (o gi√† presente)"

  data_modeling:
    name: Data Modeling (generate DDL)
    runs-on: ubuntu-latest
    needs: initialization
    if: ${{ github.event.inputs.run_data_modeling == 'true' }}
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ github.event.inputs.python_version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('models/python/db_structure_generator/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r models/python/db_structure_generator/requirements.txt
          pip install psycopg2-binary

      - name: Verify Excel file exists (modeling)
        run: |
          if [ ! -f "data/financialTracker.xlsx" ]; then
            echo "‚ùå File data/financialTracker.xlsx non trovato! (necessario per il Data Modeling)"
            exit 1
          fi
          echo "‚úÖ File Excel trovato"

      - name: Generate database structure (run generator)
        run: |
          cd models/python/db_structure_generator
          python main.py

      - name: Verify generated SQL file
        run: |
          if [ ! -f "sql/ddl/financial_tracker_ddl.sql" ]; then
            echo "‚ùå File SQL non generato!"
            exit 1
          fi
          echo "‚úÖ File SQL generato con successo"
          echo "üìä Dimensione file: $(du -h sql/ddl/financial_tracker_ddl.sql | cut -f1)"
          head -10 sql/ddl/financial_tracker_ddl.sql

      - name: Upload SQL artifact
        uses: actions/upload-artifact@v4
        with:
          name: database-ddl-${{ github.event.inputs.branch }}-py${{ github.event.inputs.python_version }}
          path: sql/ddl/financial_tracker_ddl.sql
          retention-days: 30

  data_provisioning:
    name: Data Provisioning (deploy schema to Neon)
    runs-on: ubuntu-latest
    needs: initialization
    if: ${{ github.event.inputs.run_data_provisioning == 'true' }}
    permissions:
      contents: write
    env:
      PGHOST: ${{ secrets.PGHOST }}
      PGDATABASE: ${{ secrets.PGDATABASE }}
      PGUSER: ${{ secrets.PGUSER }}
      PGPASSWORD: ${{ secrets.PGPASSWORD }}
      PGSSLMODE: ${{ secrets.PGSSLMODE }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Try download SQL artifact from this run (if Data Modeling ran)
        uses: actions/download-artifact@v4
        with:
          name: database-ddl-${{ github.event.inputs.branch }}-py${{ github.event.inputs.python_version }}
          path: sql/ddl
        continue-on-error: true

      - name: Locate SQL file (artifact or repo)
        run: |
          if [ -f "sql/ddl/financial_tracker_ddl.sql" ]; then
            echo "‚úÖ SQL file found at sql/ddl/financial_tracker_ddl.sql"
          else
            echo "‚ùå Nessun file SQL disponibile per il deploy."
            exit 1
          fi

      - name: Set up Python (for psycopg2)
        uses: actions/setup-python@v5
        with:
          python-version: ${{ github.event.inputs.python_version }}

      - name: Install psycopg2
        run: |
          python -m pip install --upgrade pip
          pip install psycopg2-binary

      - name: Deploy DDL to PostgreSQL Neon
        run: |
          echo "üöÄ Inizio deploy su PostgreSQL Neon..."
          python - <<'PY'
import psycopg2, os, sys
try:
    conn = psycopg2.connect(
        host=os.environ['PGHOST'],
        database=os.environ['PGDATABASE'],
        user=os.environ['PGUSER'],
        password=os.environ['PGPASSWORD'],
        sslmode=os.environ.get('PGSSLMODE', 'require')
    )
    with conn.cursor() as cursor:
        with open('sql/ddl/financial_tracker_ddl.sql', 'r', encoding='utf-8') as f:
            sql_content = f.read()
        cursor.execute(sql_content)
        conn.commit()
        cursor.execute("""
            SELECT schemaname, tablename 
            FROM pg_tables 
            WHERE schemaname NOT IN ('information_schema', 'pg_catalog')
            ORDER BY schemaname, tablename;
        """)
        tables = cursor.fetchall()
        print('Tabelle create:', tables)
    conn.close()
except Exception as e:
    print('Errore during DDL deploy:', e)
    sys.exit(1)
PY

  etl:
    name: ETL (populate tables)
    runs-on: ubuntu-latest
    needs: initialization
    if: ${{ github.event.inputs.run_etl == 'true' }}
    permissions:
      contents: write
    env:
      PGHOST: ${{ secrets.PGHOST }}
      PGDATABASE: ${{ secrets.PGDATABASE }}
      PGUSER: ${{ secrets.PGUSER }}
      PGPASSWORD: ${{ secrets.PGPASSWORD }}
      PGSSLMODE: ${{ secrets.PGSSLMODE }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Try download SQL artifact from this run (optional)
        uses: actions/download-artifact@v4
        with:
          name: database-ddl-${{ github.event.inputs.branch }}-py${{ github.event.inputs.python_version }}
          path: sql/ddl
        continue-on-error: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ github.event.inputs.python_version }}

      - name: Install ETL dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r models/python/db_structure_generator/requirements.txt || true
          pip install psycopg2-binary openpyxl pandas || true

      - name: Run ETL script to populate tables
        run: |
          echo "üìä Inizio ETL (popolamento tabelle)..."
          cd models/python/db_structure_generator
          python - <<'PY'
import os, sys
try:
    from config import EXCEL_FILE
    from extractor import extract_sheets
    from etl import load_dataframe_to_table
    import psycopg2
    mapping = extract_sheets(EXCEL_FILE)
    # Override connection in etl module if possible
    try:
        import etl as etl_module
        def neon_conn():
            return psycopg2.connect(
                host=os.environ['PGHOST'],
                database=os.environ['PGDATABASE'],
                user=os.environ['PGUSER'],
                password=os.environ['PGPASSWORD'],
                sslmode=os.environ.get('PGSSLMODE', 'require')
            )
        if hasattr(etl_module, 'get_connection'):
            etl_module.get_connection = neon_conn
    except Exception:
        pass
    total = 0
    for (schema, table), df in mapping.items():
        load_dataframe_to_table(schema, table, df)
        total += len(df)
    print("ETL completato, righe caricate:", total)
except Exception as e:
    print("Errore ETL:", e)
    sys.exit(1)
PY

  closure:
    name: Closure & summary
    runs-on: ubuntu-latest
    needs: [initialization, data_modeling, data_provisioning, etl]
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Display run summary
        run: |
          echo "üéâ Workflow summary"
          echo " - Branch: ${{ github.event.inputs.branch }}"
          echo " - Python: ${{ github.event.inputs.python_version }}"
          echo " - run_data_modeling: ${{ github.event.inputs.run_data_modeling }}"
          echo " - run_data_provisioning: ${{ github.event.inputs.run_data_provisioning }}"
          echo " - run_etl: ${{ github.event.inputs.run_etl }}"
          echo " - deploy_to_neon: ${{ github.event.inputs.deploy_to_neon }}"
          echo " - populate_data: ${{ github.event.inputs.populate_data }}"

      - name: Optional: Commit generated SQL back to branch (main/develop)
        if: (github.event.inputs.branch == 'main' || github.event.inputs.branch == 'develop') && github.event.inputs.run_data_modeling == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          if [ -n "$(git status --porcelain sql/ddl/)" ]; then
            git add sql/ddl/financial_tracker_ddl.sql || true
            # use a single-line commit message to avoid YAML/quote issues
            git commit -m "Auto-generated DDL: financial_tracker_ddl.sql [branch:${{ github.event.inputs.branch }} py:${{ github.event.inputs.python_version }}]" || true
            git push || true
            echo "‚úÖ File committato e pushato automaticamente"
          else
            echo "‚ÑπÔ∏è Nessuna modifica al file SQL da committare"
          fi
