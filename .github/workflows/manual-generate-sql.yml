# .github/workflows/generate-db-structure.yml
name: Generate Database Structure

on:
  workflow_dispatch:
    inputs:
      branch:
        description: "Branch da utilizzare"
        required: true
        default: "main"
        type: string
      python_version:
        description: "Versione Python"
        required: true
        default: "3.10"
        type: choice
        options:
          - "3.8"
          - "3.9"
          - "3.10"
          - "3.11"
          - "3.12"
      deploy_to_neon:
        description: "Deploy su PostgreSQL Neon (necessario per Provisioning/ETL)"
        required: true
        default: false
        type: boolean
      populate_data:
        description: "Popola tabelle con dati Excel (usato dall'ETL)"
        required: true
        default: true
        type: boolean
      run_data_modeling:
        description: "Esegui Data Modeling (genera SQL DDL)"
        required: true
        default: true
        type: boolean
      run_data_provisioning:
        description: "Esegui Data Provisioning (deploy dello schema su Neon)"
        required: true
        default: false
        type: boolean
      run_etl:
        description: "Esegui ETL (popolamento tabelle)"
        required: true
        default: false
        type: boolean

jobs:
  # -------------------------------------------------------
  # 1) Inizializzazione - SEMPRE
  # -------------------------------------------------------
  initialization:
    name: Initialization & validation
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Display workflow inputs
        run: |
          echo "ðŸš€ Workflow avviato con le seguenti opzioni:"
          echo " - Branch: ${{ github.event.inputs.branch }}"
          echo " - Python: ${{ github.event.inputs.python_version }}"
          echo " - run_data_modeling: ${{ github.event.inputs.run_data_modeling }}"
          echo " - run_data_provisioning: ${{ github.event.inputs.run_data_provisioning }}"
          echo " - run_etl: ${{ github.event.inputs.run_etl }}"
          echo " - deploy_to_neon: ${{ github.event.inputs.deploy_to_neon }}"
          echo " - populate_data: ${{ github.event.inputs.populate_data }}"

      - name: Check Excel file presence
        run: |
          if [ ! -f "data/financialTracker.xlsx" ]; then
            echo "âš ï¸ File data/financialTracker.xlsx non trovato in repo"
          else
            echo "âœ… File Excel trovato"
            ls -la data/financialTracker.xlsx
          fi

      - name: Create output directory
        run: |
          mkdir -p sql/ddl
          echo "âœ… Directory sql/ddl preparata"

  # -------------------------------------------------------
  # 2) Data Modeling - SOLO SE SELEZIONATO
  # -------------------------------------------------------
  data_modeling:
    name: Data Modeling (generate DDL)
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.run_data_modeling == 'true' }}
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ github.event.inputs.python_version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('models/python/db_structure_generator/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Create output directory
        run: |
          mkdir -p sql/ddl

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r models/python/db_structure_generator/requirements.txt
          pip install psycopg2-binary

      - name: Verify Excel file exists
        run: |
          if [ ! -f "data/financialTracker.xlsx" ]; then
            echo "âŒ File data/financialTracker.xlsx non trovato!"
            exit 1
          fi
          echo "âœ… File Excel trovato"

      - name: Generate database structure
        run: |
          cd models/python/db_structure_generator
          python main.py

      - name: Verify generated SQL file
        run: |
          if [ ! -f "sql/ddl/financial_tracker_ddl.sql" ]; then
            echo "âŒ File SQL non generato!"
            exit 1
          fi
          echo "âœ… File SQL generato con successo"
          echo "ðŸ“Š Dimensione file: $(du -h sql/ddl/financial_tracker_ddl.sql | cut -f1)"

      - name: Upload SQL artifact
        uses: actions/upload-artifact@v4
        with:
          name: database-ddl-${{ github.event.inputs.branch }}-py${{ github.event.inputs.python_version }}
          path: sql/ddl/financial_tracker_ddl.sql
          retention-days: 30

      - name: Auto-commit generated SQL
        if: github.event.inputs.branch == 'main' || github.event.inputs.branch == 'develop'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          if [ -n "$(git status --porcelain sql/ddl/)" ]; then
            git add sql/ddl/financial_tracker_ddl.sql
            git commit -m "Auto-generated DDL: financial_tracker_ddl.sql [branch:${{ github.event.inputs.branch }} py:${{ github.event.inputs.python_version }}]"
            git push
            echo "âœ… File committato e pushato automaticamente"
          else
            echo "â„¹ï¸ Nessuna modifica al file SQL da committare"
          fi

  # -------------------------------------------------------
  # 3) Data Provisioning - SOLO SE SELEZIONATO
  # -------------------------------------------------------
  data_provisioning:
    name: Data Provisioning (deploy schema to Neon)
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.run_data_provisioning == 'true' && github.event.inputs.deploy_to_neon == 'true' }}
    permissions:
      contents: write
    env:
      PGHOST: ${{ secrets.PGHOST }}
      PGDATABASE: ${{ secrets.PGDATABASE }}
      PGUSER: ${{ secrets.PGUSER }}
      PGPASSWORD: ${{ secrets.PGPASSWORD }}
      PGSSLMODE: ${{ secrets.PGSSLMODE }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ github.event.inputs.python_version }}

      - name: Install psycopg2
        run: |
          python -m pip install --upgrade pip
          pip install psycopg2-binary

      - name: Verify SQL file exists
        run: |
          if [ ! -f "sql/ddl/financial_tracker_ddl.sql" ]; then
            echo "âŒ File sql/ddl/financial_tracker_ddl.sql non trovato nel repository"
            echo "   Esegui prima il Data Modeling per generare il file DDL"
            exit 1
          fi
          echo "âœ… SQL file trovato"

      - name: Create deploy script
        run: |
          cat > deploy_ddl.py << 'EOF'
          import psycopg2, os, sys
          try:
              conn = psycopg2.connect(
                  host=os.environ['PGHOST'],
                  database=os.environ['PGDATABASE'],
                  user=os.environ['PGUSER'],
                  password=os.environ['PGPASSWORD'],
                  sslmode=os.environ.get('PGSSLMODE', 'require')
              )
              with conn.cursor() as cursor:
                  print('ðŸ“– Lettura file SQL...')
                  with open('sql/ddl/financial_tracker_ddl.sql', 'r', encoding='utf-8') as f:
                      sql_content = f.read()
                  print('ðŸ”„ Esecuzione DDL sul database...')
                  cursor.execute(sql_content)
                  conn.commit()
                  cursor.execute("""
                      SELECT schemaname, tablename 
                      FROM pg_tables 
                      WHERE schemaname NOT IN ('information_schema', 'pg_catalog')
                      ORDER BY schemaname, tablename;
                  """)
                  tables = cursor.fetchall()
                  print('ðŸ“Š Tabelle create:', len(tables))
                  for schema, table in tables:
                      print(f'   - {schema}.{table}')
              conn.close()
              print('ðŸŽ‰ DDL Deploy completato con successo!')
          except Exception as e:
              print('âŒ Errore durante il DDL deploy:', e)
              sys.exit(1)
          EOF

      - name: Deploy DDL to PostgreSQL Neon
        run: |
          echo "ðŸš€ Inizio deploy su PostgreSQL Neon..."
          python deploy_ddl.py

  # -------------------------------------------------------
  # 4) ETL - SOLO SE SELEZIONATO
  # -------------------------------------------------------
  etl:
    name: ETL (populate tables)
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.run_etl == 'true' && github.event.inputs.deploy_to_neon == 'true' }}
    permissions:
      contents: write
    env:
      PGHOST: ${{ secrets.PGHOST }}
      PGDATABASE: ${{ secrets.PGDATABASE }}
      PGUSER: ${{ secrets.PGUSER }}
      PGPASSWORD: ${{ secrets.PGPASSWORD }}
      PGSSLMODE: ${{ secrets.PGSSLMODE }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ github.event.inputs.python_version }}

      - name: Install ETL dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r models/python/db_structure_generator/requirements.txt || true
          pip install psycopg2-binary openpyxl pandas || true

      - name: Verify Excel file exists
        run: |
          if [ ! -f "data/financialTracker.xlsx" ]; then
            echo "âŒ File data/financialTracker.xlsx non trovato!"
            exit 1
          fi
          echo "âœ… File Excel trovato"

      - name: Create ETL script
        run: |
          cd models/python/db_structure_generator
          cat > run_etl.py << 'EOF'
          import os, sys
          try:
              from config import EXCEL_FILE
              from extractor import extract_sheets
              from etl import load_dataframe_to_table
              import psycopg2

              mapping = extract_sheets(EXCEL_FILE)

              # Override connection function if available
              try:
                  import etl as etl_module
                  def neon_conn():
                      return psycopg2.connect(
                          host=os.environ['PGHOST'],
                          database=os.environ['PGDATABASE'],
                          user=os.environ['PGUSER'],
                          password=os.environ['PGPASSWORD'],
                          sslmode=os.environ.get('PGSSLMODE', 'require')
                      )
                  if hasattr(etl_module, 'get_connection'):
                      etl_module.get_connection = neon_conn
              except Exception:
                  pass

              total = 0
              for (schema, table), df in mapping.items():
                  print(f'Caricamento {schema}.{table} - {len(df)} righe')
                  load_dataframe_to_table(schema, table, df)
                  total += len(df)
              print(f"âœ… ETL completato, righe caricate: {total}")
          except Exception as e:
              print(f"âŒ Errore ETL: {e}")
              sys.exit(1)
          EOF

      - name: Run ETL script to populate tables
        run: |
          echo "ðŸ“Š Inizio ETL (popolamento tabelle)..."
          cd models/python/db_structure_generator
          python run_etl.py

  # -------------------------------------------------------
  # 5) Chiusura - SEMPRE
  # -------------------------------------------------------
  closure:
    name: Closure & summary
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Display run summary
        run: |
          echo "ðŸŽ‰ Workflow summary"
          echo " - Branch: ${{ github.event.inputs.branch }}"
          echo " - Python: ${{ github.event.inputs.python_version }}"
          echo " - run_data_modeling: ${{ github.event.inputs.run_data_modeling }}"
          echo " - run_data_provisioning: ${{ github.event.inputs.run_data_provisioning }}"
          echo " - run_etl: ${{ github.event.inputs.run_etl }}"
          echo " - deploy_to_neon: ${{ github.event.inputs.deploy_to_neon }}"
          echo " - populate_data: ${{ github.event.inputs.populate_data }}"
